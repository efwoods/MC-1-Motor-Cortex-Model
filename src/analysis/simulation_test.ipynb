{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efebb32b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Get absolute path to 'src' folder relative to this notebook\n",
    "src_path = os.path.abspath(os.path.join(os.getcwd(), '..'))\n",
    "if src_path not in sys.path:\n",
    "    sys.path.insert(0, src_path)\n",
    "\n",
    "# Imports\n",
    "\n",
    "import os\n",
    "import gc\n",
    "from glob import glob\n",
    "import joblib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "# Scipy\n",
    "from scipy.signal import butter, filtfilt, iirnotch, hilbert\n",
    "from scipy.stats import kurtosis\n",
    "from scipy.io import savemat \n",
    "\n",
    "# Scikit-Learn\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "# Pytorch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torch.utils.data import random_split\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "\n",
    "# Settings\n",
    "CONTRALATERAL_BASE_PATH =  '../data/'\n",
    "DATA_ROOT_PATH = '/home/linux-pc/gh/projects/NeuralNexus/New-Features/Thought-to-Motion/CRCNS/src/motor_cortex/data/data/Contralateral/2018-04-12_(S4)/'\n",
    "\n",
    "ECOG_DATA_FILENAME = 'Contralateral_2018-04-12_(S4)_cleaned_aligned_ecog_data.csv'\n",
    "MOTION_DATA_FILENAME = 'Contralateral_2018-04-12_(S4)_cleaned_aligned_motion_data.csv'\n",
    "\n",
    "ECOG_DATA_FILENAME_DATA_ONLY = 'Contralateral_2018-04-12_(S4)_cleaned_aligned_ecog_data_DATA_ONLY.csv'\n",
    "MOTION_DATA_FILENAME_DATA_ONLY = 'Contralateral_2018-04-12_(S4)_cleaned_aligned_motion_data_DATA_ONLY.csv'\n",
    "\n",
    "CONTRALATERAL_ECOG_DATA_FULL_FILE_PATH = CONTRALATERAL_BASE_PATH + ECOG_DATA_FILENAME\n",
    "CONTRALATERAL_MOTION_DATA_FULL_FILE_PATH = CONTRALATERAL_BASE_PATH + MOTION_DATA_FILENAME\n",
    "\n",
    "\n",
    "MOTION_NP = \"../data/motion_values_normalized.npy\"\n",
    "ECOG_NP = \"../data/ecog_values_normalized.npy\"\n",
    "\n",
    "from models.dataset import MotionECoGDataset\n",
    "\n",
    "from torch.utils.data import Subset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Model Classes\n",
    "from models.variational_motion_encoder import VariationalMotionEncoder\n",
    "from models.waveform_decoder import WaveformDecoder\n",
    "from models.variational_waveform_encoder import VariationalWaveformEncoder\n",
    "from models.motion_decoder import MotionDecoder\n",
    "from models.spasm_dataset import SpasmDataset\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.graph_objects as go\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Paths to models\n",
    "model_paths = {\n",
    "    \"motion_encoder\": \"../models/motion_encoder_best.pt\",\n",
    "    \"waveform_decoder\": \"../models/waveform_decoder_best.pt\",\n",
    "    \"waveform_encoder\": \"../models/waveform_encoder_best.pt\",\n",
    "    \"motion_decoder\": \"../models/motion_decoder_best.pt\",\n",
    "}\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9ab1017",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def add_spasms_to_motion(data, num_spasms=10, spasm_duration=5, max_amplitude=0.2, seed=None):\n",
    "    \"\"\"\n",
    "    Adds simulated spasms to a 3D motion trajectory.\n",
    "\n",
    "    Parameters:\n",
    "    - data: np.ndarray of shape (N, 3), the original xyz coordinates.\n",
    "    - num_spasms: number of distinct spasm events to simulate.\n",
    "    - spasm_duration: how many consecutive frames each spasm lasts.\n",
    "    - max_amplitude: maximum displacement of spasm noise.\n",
    "    - seed: random seed for reproducibility.\n",
    "\n",
    "    Returns:\n",
    "    - spasm_data: modified data with added spasms.\n",
    "    - spasm_indices: indices where spasms occurred.\n",
    "    \"\"\"\n",
    "    if seed is not None:\n",
    "        np.random.seed(seed)\n",
    "\n",
    "    data = data.copy()\n",
    "    total_frames = data.shape[0]\n",
    "\n",
    "    spasm_indices = np.sort(np.random.choice(\n",
    "        total_frames - spasm_duration, num_spasms, replace=False))\n",
    "\n",
    "    for idx in spasm_indices:\n",
    "        for i in range(spasm_duration):\n",
    "            noise = np.random.normal(loc=0.0, scale=max_amplitude, size=3)\n",
    "            data[idx + i] += noise\n",
    "\n",
    "    return data, spasm_indices\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd584c40",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "033c42e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = MotionECoGDataset(MOTION_NP, ECOG_NP)\n",
    "test_indices = torch.load(\"../models/test_indices.pt\")\n",
    "test_dataset = Subset(dataset, test_indices)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False, drop_last=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90c14326",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiating the Model Classes\n",
    "\n",
    "# Initialize models\n",
    "latent_dim = 128\n",
    "motion_encoder = VariationalMotionEncoder(latent_dim=latent_dim).to(device)\n",
    "# MotionEncoder(latent_dim).to(device)\n",
    "waveform_decoder = WaveformDecoder(latent_dim=latent_dim).to(device)\n",
    "waveform_encoder = VariationalWaveformEncoder(\n",
    "    input_dim=64, hidden_dim=128, latent_dim=128\n",
    ").to(device)\n",
    "# WaveformEncoder(latent_dim).to(device)\n",
    "motion_decoder = MotionDecoder(latent_dim).to(device)\n",
    "\n",
    "# Load the Models\n",
    "motion_encoder.load_state_dict(torch.load(model_paths[\"motion_encoder\"], map_location=device))\n",
    "waveform_decoder.load_state_dict(torch.load(model_paths[\"waveform_decoder\"], map_location=device))\n",
    "waveform_encoder.load_state_dict(torch.load(model_paths[\"waveform_encoder\"], map_location=device))\n",
    "motion_decoder.load_state_dict(torch.load(model_paths[\"motion_decoder\"], map_location=device))\n",
    "\n",
    "# Set to eval mode\n",
    "motion_encoder.eval()\n",
    "waveform_decoder.eval()\n",
    "waveform_encoder.eval()\n",
    "motion_decoder.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "738e15e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "GLOBAL_MOTION_STD = np.load('../data/global_motion_std.npy')\n",
    "GLOBAL_MOTION_MEAN = np.load('../data/global_motion_mean.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44b10ba9",
   "metadata": {},
   "source": [
    "## Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53cd4e0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "motion_np = \"../data/motion_values_normalized.npy\"\n",
    "ecog_np = \"../data/ecog_values_normalized.npy\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91aea0db",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_split = 0.2\n",
    "test_split = 0.1\n",
    "batch_size = 128\n",
    "epochs=300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00b0dc21",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = MotionECoGDataset(motion_np, ecog_np)\n",
    "total_length = len(dataset)\n",
    "test_size = int(test_split * total_length)\n",
    "remaining_size = total_length - test_size\n",
    "val_size = int(val_split * remaining_size)\n",
    "train_size = remaining_size - val_size\n",
    "train_dataset, val_dataset, test_dataset = random_split(\n",
    "    dataset, [train_size, val_size, test_size]\n",
    ")\n",
    "train_loader = DataLoader(\n",
    "    train_dataset, batch_size=batch_size, shuffle=True, drop_last=True\n",
    ")\n",
    "val_loader = DataLoader(\n",
    "    val_dataset, batch_size=batch_size, shuffle=False, drop_last=True\n",
    ")\n",
    "test_loader = DataLoader(\n",
    "    test_dataset, batch_size=batch_size, shuffle=False, drop_last=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a99e3dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(epochs):\n",
    "    for batch in tqdm(test_dataset_sample.indices[\"test_indices\"], desc=f\"Epoch {epoch+1}/{epochs}\"):\n",
    "                motion = batch[\"motion\"].to(device)\n",
    "                ecog = batch[\"ecog\"].to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b83906a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f401519",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset.indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfb1a852",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_sample = MotionECoGDataset(MOTION_NP, ECOG_NP)\n",
    "test_indices_sample = torch.load(\"../models/test_indices.pt\")\n",
    "test_dataset_sample = Subset(dataset_sample, test_indices_sample)\n",
    "test_loader_sample = DataLoader(test_dataset_sample, batch_size=64, shuffle=False, drop_last=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd190cfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(epochs):\n",
    "    for batch in tqdm(test_loader_sample, desc=f\"Epoch {epoch+1}/{epochs}\"):\n",
    "                motion = batch[\"motion\"].to(device)\n",
    "                ecog = batch[\"ecog\"].to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a72149d",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76f3e677",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c03c92ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader_2 = DataLoader(\n",
    "    test_dataset_sample, batch_size=batch_size, shuffle=False, drop_last=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e10e7fd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "837de8b6",
   "metadata": {},
   "source": [
    "## Reconstruction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86496f3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Collect motion predictions\n",
    "predicted_coordinates = []\n",
    "actual_coordinates = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in tqdm(test_loader, desc=\"Generating Motion Predictions\"):\n",
    "        motion = batch[\"motion\"].to(device)\n",
    "        ecog = batch[\"ecog\"].to(device)\n",
    "\n",
    "        # Full latent pass\n",
    "        motion_latent, _, _ = motion_encoder(motion)\n",
    "        ecog_synth = waveform_decoder(motion_latent)\n",
    "        waveform_latent, _, _ = waveform_encoder(ecog_synth)\n",
    "        motion_reconstructed = motion_decoder(waveform_latent)\n",
    "\n",
    "        # motion_reconstructed shape: (B, 3)\n",
    "        # Normalize back to the real space\n",
    "\n",
    "        predicted_coordinates.append((motion_reconstructed.cpu().numpy() * GLOBAL_MOTION_STD) + GLOBAL_MOTION_MEAN)\n",
    "        actual_coordinates.append((motion.cpu().numpy() * GLOBAL_MOTION_STD) + GLOBAL_MOTION_MEAN)\n",
    "\n",
    "predicted_coords = np.concatenate(predicted_coordinates, axis=0)\n",
    "actual_coordinates = np.concatenate(actual_coordinates, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50f46d26",
   "metadata": {},
   "source": [
    "## Visualization\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8503e33b",
   "metadata": {},
   "source": [
    "### Single Instance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "098ea2f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "import numpy as np\n",
    "\n",
    "# Downsample for clarity (every 10th point)\n",
    "step = 10\n",
    "actual = actual_coordinates[::step]\n",
    "predicted = predicted_coords[::step]\n",
    "\n",
    "fig = go.Figure()\n",
    "\n",
    "# Actual Trajectory\n",
    "fig.add_trace(go.Scatter3d(\n",
    "    x=actual[:, 0], y=actual[:, 1], z=actual[:, 2],\n",
    "    mode='lines+markers',\n",
    "    marker=dict(size=3, color='green'),\n",
    "    line=dict(color='green', width=4),\n",
    "    name='Actual Motion'\n",
    "))\n",
    "\n",
    "# Predicted Trajectory\n",
    "fig.add_trace(go.Scatter3d(\n",
    "    x=predicted[:, 0], y=predicted[:, 1], z=predicted[:, 2],\n",
    "    mode='lines+markers',\n",
    "    marker=dict(size=3, color='red'),\n",
    "    line=dict(color='red', width=4),\n",
    "    name='Predicted Motion'\n",
    "))\n",
    "\n",
    "fig.update_layout(\n",
    "    title=\"Predicted vs Actual 3D Wrist Motion\",\n",
    "    scene=dict(\n",
    "        xaxis_title='X',\n",
    "        yaxis_title='Y',\n",
    "        zaxis_title='Z',\n",
    "    ),\n",
    "    margin=dict(l=0, r=0, b=0, t=40),\n",
    "    legend=dict(x=0.7, y=0.9)\n",
    ")\n",
    "\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "198b86d3",
   "metadata": {},
   "source": [
    "### Temporal Development Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7c26890",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "import numpy as np\n",
    "n_frames = 1\n",
    "# Downsample\n",
    "step = 10\n",
    "actual = actual_coordinates[::step]\n",
    "predicted = predicted_coords[::step]\n",
    "N = actual.shape[0]\n",
    "\n",
    "# Create frames\n",
    "frames = [\n",
    "    go.Frame(\n",
    "        data=[\n",
    "            go.Scatter3d(\n",
    "                x=actual[:k, 0], y=actual[:k, 1], z=actual[:k, 2],\n",
    "                mode='lines+markers',\n",
    "                line=dict(color='green', width=4),\n",
    "                marker=dict(size=3, color='green'),\n",
    "                name='Actual'\n",
    "            ),\n",
    "            go.Scatter3d(\n",
    "                x=predicted[:k, 0], y=predicted[:k, 1], z=predicted[:k, 2],\n",
    "                mode='lines+markers',\n",
    "                line=dict(color='red', width=4),\n",
    "                marker=dict(size=3, color='red'),\n",
    "                name='Predicted'\n",
    "            )\n",
    "        ],\n",
    "        name=str(k)\n",
    "    )\n",
    "    for k in range(1, N + 1)\n",
    "]\n",
    "\n",
    "# Initial trace\n",
    "fig = go.Figure(data=[\n",
    "    go.Scatter3d(\n",
    "        x=[actual[0, 0]], y=[actual[0, 1]], z=[actual[0, 2]],\n",
    "        mode='markers', marker=dict(size=5, color='green'), name='Actual'\n",
    "    ),\n",
    "    go.Scatter3d(\n",
    "        x=[predicted[0, 0]], y=[predicted[0, 1]], z=[predicted[0, 2]],\n",
    "        mode='markers', marker=dict(size=5, color='red'), name='Predicted'\n",
    "    )\n",
    "], frames=frames)\n",
    "\n",
    "# Layout and controls\n",
    "fig.update_layout(\n",
    "    title='Animated 3D Wrist Motion: Predicted vs Actual',\n",
    "    scene=dict(\n",
    "        xaxis=dict(range=[min(actual[:, 0].min(), predicted[:, 0].min()),\n",
    "                          max(actual[:, 0].max(), predicted[:, 0].max())], title='X'),\n",
    "        yaxis=dict(range=[min(actual[:, 1].min(), predicted[:, 1].min()),\n",
    "                          max(actual[:, 1].max(), predicted[:, 1].max())], title='Y'),\n",
    "        zaxis=dict(range=[min(actual[:, 2].min(), predicted[:, 2].min()),\n",
    "                          max(actual[:, 2].max(), predicted[:, 2].max())], title='Z'),\n",
    "    ),\n",
    "    updatemenus=[dict(\n",
    "        type='buttons',\n",
    "        showactive=False,\n",
    "        buttons=[\n",
    "            dict(\n",
    "                label='Play',\n",
    "                method='animate',\n",
    "                args=[None, dict(frame=dict(duration=20, redraw=True), fromcurrent=True, mode='immediate')]\n",
    "            ),\n",
    "            dict(\n",
    "                label='Pause',\n",
    "                method='animate',\n",
    "                args=[[None], dict(frame=dict(duration=0, redraw=False), mode='immediate')]\n",
    "            )\n",
    "        ],\n",
    "        x=0.1, y=0, xanchor='right', yanchor='top'\n",
    "    )],\n",
    "    sliders=[dict(\n",
    "        active=0,\n",
    "        pad=dict(t=50),\n",
    "        steps=[\n",
    "            dict(\n",
    "                method='animate',\n",
    "                args=[[str(k)], dict(mode='immediate', frame=dict(duration=0, redraw=True), transition=dict(duration=0))],\n",
    "                label=str(k)\n",
    "            )\n",
    "            for k in range(1, N + 1, n_frames)\n",
    "        ]\n",
    "    )]\n",
    ")\n",
    "\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60ade492",
   "metadata": {},
   "source": [
    "## Actual Motion Only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "157d2bcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "actual_coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2f8cba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "import numpy as np\n",
    "\n",
    "# Downsample for clarity (every 10th point)\n",
    "step = 10\n",
    "actual = actual_coordinates[::step]\n",
    "predicted = predicted_coords[::step]\n",
    "\n",
    "fig = go.Figure()\n",
    "\n",
    "# Actual Trajectory\n",
    "fig.add_trace(go.Scatter3d(\n",
    "    x=actual[:, 0], y=actual[:, 1], z=actual[:, 2],\n",
    "    mode='lines+markers',\n",
    "    marker=dict(size=3, color='purple'),\n",
    "    line=dict(color='teal', width=4),\n",
    "    name='Actual Motion'\n",
    "))\n",
    "\n",
    "# Predicted Trajectory\n",
    "# fig.add_trace(go.Scatter3d(\n",
    "#     x=predicted[:, 0], y=predicted[:, 1], z=predicted[:, 2],\n",
    "#     mode='lines+markers',\n",
    "#     marker=dict(size=3, color='red'),\n",
    "#     line=dict(color='red', width=4),\n",
    "#     name='Predicted Motion'\n",
    "# ))\n",
    "\n",
    "fig.update_layout(\n",
    "    title=\"Actual 3D Wrist Motion\",\n",
    "    scene=dict(\n",
    "        xaxis_title='X',\n",
    "        yaxis_title='Y',\n",
    "        zaxis_title='Z',\n",
    "    ),\n",
    "    margin=dict(l=0, r=0, b=0, t=40),\n",
    "    legend=dict(x=0.7, y=0.9)\n",
    ")\n",
    "\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a838e9d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "import numpy as np\n",
    "n_frames = 1\n",
    "# Downsample\n",
    "step = 2\n",
    "actual = actual_coordinates[::step]\n",
    "# predicted = predicted_coords[::step]\n",
    "N = actual.shape[0]\n",
    "\n",
    "# Create frames\n",
    "frames = [\n",
    "    go.Frame(\n",
    "        data=[\n",
    "            go.Scatter3d(\n",
    "                x=actual[:k, 0], y=actual[:k, 1], z=actual[:k, 2],\n",
    "                mode='lines+markers',\n",
    "                line=dict(color='purple', width=4),\n",
    "                marker=dict(size=3, color='teal'),\n",
    "                name='Actual'\n",
    "            ),\n",
    "            # go.Scatter3d(\n",
    "            #     x=predicted[:k, 0], y=predicted[:k, 1], z=predicted[:k, 2],\n",
    "            #     mode='lines+markers',\n",
    "            #     line=dict(color='red', width=4),\n",
    "            #     marker=dict(size=3, color='red'),\n",
    "            #     name='Predicted'\n",
    "            # )\n",
    "        ],\n",
    "        name=str(k)\n",
    "    )\n",
    "    for k in range(1, N + 1)\n",
    "]\n",
    "\n",
    "# Initial trace\n",
    "fig = go.Figure(data=[\n",
    "    go.Scatter3d(\n",
    "        x=[actual[0, 0]], y=[actual[0, 1]], z=[actual[0, 2]],\n",
    "        mode='markers', marker=dict(size=5, color='teal'), name='Actual'\n",
    "    ),\n",
    "    # go.Scatter3d(\n",
    "    #     x=[predicted[0, 0]], y=[predicted[0, 1]], z=[predicted[0, 2]],\n",
    "    #     mode='markers', marker=dict(size=5, color='red'), name='Predicted'\n",
    "    # )\n",
    "], frames=frames)\n",
    "\n",
    "# Layout and controls\n",
    "fig.update_layout(\n",
    "    title='Animated 3D Wrist Motion: Actual',\n",
    "    scene=dict(\n",
    "        xaxis=dict(range=[actual[:, 0].min(),\n",
    "                          actual[:, 0].max()], title='X'),\n",
    "        yaxis=dict(range=[actual[:, 1].min(),\n",
    "                          actual[:, 1].max()], title='Y'),\n",
    "        zaxis=dict(range=[actual[:, 2].min(),\n",
    "                          actual[:, 2].max()], title='Z'),\n",
    "    ),\n",
    "    updatemenus=[dict(\n",
    "        type='buttons',\n",
    "        showactive=False,\n",
    "        buttons=[\n",
    "            dict(\n",
    "                label='Play',\n",
    "                method='animate',\n",
    "                args=[None, dict(frame=dict(duration=20, redraw=True), fromcurrent=True, mode='immediate')]\n",
    "            ),\n",
    "            dict(\n",
    "                label='Pause',\n",
    "                method='animate',\n",
    "                args=[[None], dict(frame=dict(duration=0, redraw=False), mode='immediate')]\n",
    "            )\n",
    "        ],\n",
    "        x=0.1, y=0, xanchor='right', yanchor='top'\n",
    "    )],\n",
    "    sliders=[dict(\n",
    "        active=0,\n",
    "        pad=dict(t=50),\n",
    "        steps=[\n",
    "            dict(\n",
    "                method='animate',\n",
    "                args=[[str(k)], dict(mode='immediate', frame=dict(duration=0, redraw=True), transition=dict(duration=0))],\n",
    "                label=str(k)\n",
    "            )\n",
    "            for k in range(1, N + 1, n_frames)\n",
    "        ]\n",
    "    )]\n",
    ")\n",
    "\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c1e30de",
   "metadata": {},
   "source": [
    "## Simulating spasms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "632dd0b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Physical Movements with introduced jitter\n",
    "# Create Synthetic Waveforms from this new dataset\n",
    "# Detect Anomalies in the synthetic waveforms in real time\n",
    "# Calculate the Counter Current\n",
    "# Calculate the Adjusted Signal after this current is introduced\n",
    "# Reconstruct the physical motion (proceed as normal) \n",
    "# Evaluate Results (Original Motion should be the same as Hyperpolarized Reconstructed Spasm Motion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcdf6e28",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "SPASM_DURATION = 50 # Samples (sampling rate is 50 Hz)\n",
    "\n",
    "# Assuming actual_coordinates and spasm_data are defined\n",
    "spasm_data, spasm_indices = add_spasms_to_motion(\n",
    "    actual_coordinates,\n",
    "    num_spasms=15,\n",
    "    spasm_duration=SPASM_DURATION,\n",
    "    max_amplitude=0.2,\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(spasm_data[:, 0], label='Spasm X', linewidth=1.2)\n",
    "plt.plot(actual_coordinates[:, 0], label='Original X', linewidth=0.6)\n",
    "\n",
    "# Highlight spasm durations\n",
    "for idx in spasm_indices:\n",
    "    start = idx\n",
    "    end = idx + SPASM_DURATION  # spasm_duration\n",
    "    plt.axvspan(start, end, color='red', alpha=0.15)\n",
    "\n",
    "plt.title('X Coordinate with Highlighted Spasm Durations')\n",
    "plt.xlabel('Frame Index')\n",
    "plt.ylabel('X Position')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "343156c0",
   "metadata": {},
   "source": [
    "Rationale behind simulated spasms hyperparameters:\n",
    "\n",
    "\n",
    "The rhesus macaque has an armspan of approximately 2 feet. The units of this data are unlisted so I am taking the liberty to assert that they are units of feet given that the monkey is reaching for food on the table and placing it in its mouth. Given this, I am introducing 0.2 of a foot into this system indicating 2.4 inches of spasm for 50 samples. At 50 Hz, the spasm is a single second. Spasms typically are up to 15 cm, but 2.4 inches for a spasm does not seem outlandish and falls within the context of the reality of the problem. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "608c8742",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "import numpy as np\n",
    "n_frames = 1\n",
    "# Downsample\n",
    "step = 2\n",
    "spasm = spasm_data[::step]\n",
    "\n",
    "N = spasm.shape[0]\n",
    "\n",
    "# Create frames\n",
    "frames = [\n",
    "    go.Frame(\n",
    "        data=[\n",
    "            go.Scatter3d(\n",
    "                x=spasm[:k, 0], y=spasm[:k, 1], z=spasm[:k, 2],\n",
    "                mode='lines+markers',\n",
    "                line=dict(color='purple', width=4),\n",
    "                marker=dict(size=3, color='teal'),\n",
    "                name='Actual'\n",
    "            ),\n",
    "        ],\n",
    "        name=str(k)\n",
    "    )\n",
    "    for k in range(1, N + 1)\n",
    "]\n",
    "\n",
    "# Initial trace\n",
    "fig = go.Figure(data=[\n",
    "    go.Scatter3d(\n",
    "        x=[spasm[0, 0]], y=[spasm[0, 1]], z=[spasm[0, 2]],\n",
    "        mode='markers', marker=dict(size=5, color='teal'), name='Actual'\n",
    "    ),\n",
    "\n",
    "], frames=frames)\n",
    "\n",
    "# Layout and controls\n",
    "fig.update_layout(\n",
    "    title='Animated 3D Wrist Motion: Simulated Spasms',\n",
    "    scene=dict(\n",
    "        xaxis=dict(range=[spasm[:, 0].min(),\n",
    "                          spasm[:, 0].max()], title='X'),\n",
    "        yaxis=dict(range=[spasm[:, 1].min(),\n",
    "                          spasm[:, 1].max()], title='Y'),\n",
    "        zaxis=dict(range=[spasm[:, 2].min(),\n",
    "                          spasm[:, 2].max()], title='Z'),\n",
    "    ),\n",
    "    updatemenus=[dict(\n",
    "        type='buttons',\n",
    "        showactive=False,\n",
    "        buttons=[\n",
    "            dict(\n",
    "                label='Play',\n",
    "                method='animate',\n",
    "                args=[None, dict(frame=dict(duration=20, redraw=True), fromcurrent=True, mode='immediate')]\n",
    "            ),\n",
    "            dict(\n",
    "                label='Pause',\n",
    "                method='animate',\n",
    "                args=[[None], dict(frame=dict(duration=0, redraw=False), mode='immediate')]\n",
    "            )\n",
    "        ],\n",
    "        x=0.1, y=0, xanchor='right', yanchor='top'\n",
    "    )],\n",
    "    sliders=[dict(\n",
    "        active=0,\n",
    "        pad=dict(t=50),\n",
    "        steps=[\n",
    "            dict(\n",
    "                method='animate',\n",
    "                args=[[str(k)], dict(mode='immediate', frame=dict(duration=0, redraw=True), transition=dict(duration=0))],\n",
    "                label=str(k)\n",
    "            )\n",
    "            for k in range(1, N + 1, n_frames)\n",
    "        ]\n",
    "    )]\n",
    ")\n",
    "\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee7a87d5",
   "metadata": {},
   "source": [
    "## Creating Random Sythetic Spasm Waveforms: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07969b9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "actual_coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f51d938d",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.tensor(actual_coordinates[0], device=device, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a164a5cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "latents, mean, logvar = motion_encoder(torch.tensor(actual_coordinates[0], device=device, dtype=torch.float32).unsqueeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ea0c1fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "latents.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90d75ed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "spasm_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "826d4a37",
   "metadata": {},
   "outputs": [],
   "source": [
    "for spasm_sample in spasm_data:\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "329f04d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d495fe12",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(test_dataset) / "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "831af932",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(spasm_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bcaf0fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "spasm_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d090d173",
   "metadata": {},
   "outputs": [],
   "source": [
    "spasm_data = spasm_data.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5225baf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "spasm_data.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28ae1996",
   "metadata": {},
   "outputs": [],
   "source": [
    "spasm_dataset = SpasmDataset(spasm_data, spasm_indices)\n",
    "spasm_data_loader = DataLoader(spasm_dataset, batch_size=64, shuffle=False)\n",
    "ecog_synth_spasm_all = []\n",
    "# Collect motion predictions\n",
    "with torch.no_grad():\n",
    "    for batch in tqdm(spasm_data_loader, desc=\"Generating Simulated Spasm Waveforms\"):\n",
    "        spasm = batch[\"spasm\"].to(device)\n",
    "\n",
    "        # Full latent pass\n",
    "        motion_latent, _, _ = motion_encoder(spasm)\n",
    "        ecog_synth_spasm = waveform_decoder(motion_latent)\n",
    "        # waveform_latent, _, _ = waveform_encoder(ecog_synth)\n",
    "        # motion_reconstructed = motion_decoder(waveform_latent)\n",
    "\n",
    "        # motion_reconstructed shape: (B, 3)\n",
    "        # Normalize back to the real space\n",
    "\n",
    "        ecog_synth_spasm_all.append(ecog_synth_spasm.cpu().numpy())\n",
    "\n",
    "ecog_synth_spasm_all = np.concatenate(ecog_synth_spasm_all, axis=0)\n",
    "spasm_dataset.ecog_synth_spasms = ecog_synth_spasm_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da0e3cbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "spasm_dataset.ecog_synth_spasms.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcd08470",
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.save(\"../data/simulated_spasm_data.npy\", spasm_dataset.spasm_data)\n",
    "# np.save(\"../data/simulated_spasm_indices.npy\", spasm_dataset.spasm_indices)\n",
    "# np.save(\"../data/ecog_synth_spasms.npy\", spasm_dataset.ecog_synth_spasms)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f49b422",
   "metadata": {},
   "source": [
    "## Load Simulated Spasm Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f90801a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "spasm_data = np.load(\"../data/simulated_spasm_data.npy\")\n",
    "spasm_indices = np.load(\"../data/simulated_spasm_indices.npy\")\n",
    "ecog_synth_spasms = np.load(\"../data/ecog_synth_spasms.npy\")\n",
    "\n",
    "spasm_dataset = SpasmDataset(spasm_data, spasm_indices, ecog_synth_spasms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "738e14ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "spasm_dataset.ecog_synth_spasms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "822785dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "spasm_dataset.spasm_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2b1769b",
   "metadata": {},
   "source": [
    "## Detecting Onset of spasms (Anomalies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "921a3258",
   "metadata": {},
   "outputs": [],
   "source": [
    "spasm_dataset.ecog_synth_spasms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2313bf6",
   "metadata": {},
   "source": [
    "### Analysis: comparing the ecog of non-spasm data at the same timestep as the spasms data ecog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cbbb4de",
   "metadata": {},
   "outputs": [],
   "source": [
    "actual_coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fac2bf66",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    Note: These are NOT spasms. They are real physical movements translated into synthetic waveforms with indices corresponding to the spasm dataset\n",
    "\"\"\"\n",
    "\n",
    "actual_coordinates_with_spasm_indices_dataset = SpasmDataset(actual_coordinates.astype(np.float32), spasm_indices)\n",
    "actual_coordinates_with_spasm_indices_dataloader = DataLoader(actual_coordinates_with_spasm_indices_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "ecog_synth_spasm_all = []\n",
    "\n",
    "# Collect motion predictions\n",
    "with torch.no_grad():\n",
    "    for batch in tqdm(actual_coordinates_with_spasm_indices_dataloader, desc=\"Generating Simulated ECoG Waveforms\"):\n",
    "        spasm = batch[\"spasm\"].to(device)\n",
    "\n",
    "        # Full latent pass\n",
    "        motion_latent, _, _ = motion_encoder(spasm)\n",
    "        ecog_synth_spasm = waveform_decoder(motion_latent)\n",
    "        # waveform_latent, _, _ = waveform_encoder(ecog_synth)\n",
    "        # motion_reconstructed = motion_decoder(waveform_latent)\n",
    "\n",
    "        # motion_reconstructed shape: (B, 3)\n",
    "        # Normalize back to the real space\n",
    "\n",
    "        ecog_synth_spasm_all.append(ecog_synth_spasm.cpu().numpy())\n",
    "\n",
    "ecog_synth_spasm_all = np.concatenate(ecog_synth_spasm_all, axis=0)\n",
    "actual_coordinates_with_spasm_indices_dataset.ecog_synth_spasms = ecog_synth_spasm_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aa5cf33",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf24c1fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "spasm_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eef0b62",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_indices = len(actual_coordinates_with_spasm_indices_dataset.ecog_synth_spasms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18cd96f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "736f5b0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all indices from 0 to N-1\n",
    "all_indices = np.arange(max_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8b302c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "non_spasm_indices = np.setdiff1d(all_indices, actual_coordinates_with_spasm_indices_dataset.spasm_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1655b38d",
   "metadata": {},
   "outputs": [],
   "source": [
    "non_spasm_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8eff605",
   "metadata": {},
   "outputs": [],
   "source": [
    "actual_coordinates_with_spasm_indices_dataset.ecog_synth_spasms[non_spasm_indices][0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dfcc0e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sample_idx = 0\n",
    "plt.figure(figsize=(12, 6))\n",
    "for ch in range(0,64):\n",
    "    plt.plot(actual_coordinates_with_spasm_indices_dataset.ecog_synth_spasms[non_spasm_indices][sample_idx][:, ch], label=f'Ch {ch}')\n",
    "    \n",
    "plt.title(f'Sample #{sample_idx}: True ECoG Synthetic Waveform Across Time')\n",
    "plt.xlabel('Time Step (0–19)')\n",
    "plt.ylabel('Amplitude')\n",
    "# plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30d4def5",
   "metadata": {},
   "outputs": [],
   "source": [
    "actual_coordinates_with_spasm_indices_dataset.ecog_synth_spasms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbfe5255",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sample_idx = 0\n",
    "spasm_idx = 0\n",
    "plt.figure(figsize=(12, 6))\n",
    "for ch in range(0,64):\n",
    "    plt.plot(actual_coordinates_with_spasm_indices_dataset.ecog_synth_spasms[spasm_dataset.spasm_indices[0]][:, ch], label=f'Ch {ch}')\n",
    "    \n",
    "plt.title(f'Sample #{sample_idx}: True ECoG Synthetic Waveform Across Time')\n",
    "plt.xlabel('Time Step (0–19)')\n",
    "plt.ylabel('Amplitude')\n",
    "# plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e369a67",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sample_idx = 0\n",
    "spasm_idx = 0\n",
    "plt.figure(figsize=(12, 6))\n",
    "for ch in range(0,64):\n",
    "    plt.plot(spasm_dataset.ecog_synth_spasms[spasm_dataset.spasm_indices[0]][:, ch], label=f'Ch {ch}')\n",
    "    \n",
    "plt.title(f'Sample #{sample_idx}: True ECoG Synthetic Waveform Across Time')\n",
    "plt.xlabel('Time Step (0–19)')\n",
    "plt.ylabel('Amplitude')\n",
    "# plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fda5fb3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "spasm_dataset.ecog_synth_spasms[spasm_dataset.spasm_indices[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f129b61",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "62c34c77",
   "metadata": {},
   "source": [
    "## Hodgkin & Huxley Calculation of Current to Induce Hyperpolarization and prevent Simulated Spasms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a8db058",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7dc57077",
   "metadata": {},
   "source": [
    "## Simulate Detecting Onset and Preventing Spasms to Create Laminar or Normal Healthy Motion "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
