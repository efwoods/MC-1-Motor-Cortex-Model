{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efebb32b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Get absolute path to 'src' folder relative to this notebook\n",
    "src_path = os.path.abspath(os.path.join(os.getcwd(), '..'))\n",
    "if src_path not in sys.path:\n",
    "    sys.path.insert(0, src_path)\n",
    "\n",
    "# Imports\n",
    "\n",
    "import os\n",
    "import gc\n",
    "from glob import glob\n",
    "import joblib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "# Scipy\n",
    "from scipy.signal import butter, filtfilt, iirnotch, hilbert\n",
    "from scipy.stats import kurtosis\n",
    "from scipy.io import savemat \n",
    "\n",
    "# Scikit-Learn\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "# Pytorch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torch.utils.data import random_split\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "\n",
    "# Settings\n",
    "CONTRALATERAL_BASE_PATH =  '../data/'\n",
    "DATA_ROOT_PATH = '/home/linux-pc/gh/projects/NeuralNexus/New-Features/Thought-to-Motion/CRCNS/src/motor_cortex/data/data/Contralateral/2018-04-12_(S4)/'\n",
    "\n",
    "ECOG_DATA_FILENAME = 'Contralateral_2018-04-12_(S4)_cleaned_aligned_ecog_data.csv'\n",
    "MOTION_DATA_FILENAME = 'Contralateral_2018-04-12_(S4)_cleaned_aligned_motion_data.csv'\n",
    "\n",
    "ECOG_DATA_FILENAME_DATA_ONLY = 'Contralateral_2018-04-12_(S4)_cleaned_aligned_ecog_data_DATA_ONLY.csv'\n",
    "MOTION_DATA_FILENAME_DATA_ONLY = 'Contralateral_2018-04-12_(S4)_cleaned_aligned_motion_data_DATA_ONLY.csv'\n",
    "\n",
    "CONTRALATERAL_ECOG_DATA_FULL_FILE_PATH = CONTRALATERAL_BASE_PATH + ECOG_DATA_FILENAME\n",
    "CONTRALATERAL_MOTION_DATA_FULL_FILE_PATH = CONTRALATERAL_BASE_PATH + MOTION_DATA_FILENAME\n",
    "\n",
    "\n",
    "MOTION_NP = \"../data/motion_values_normalized.npy\"\n",
    "ECOG_NP = \"../data/ecog_values_normalized.npy\"\n",
    "\n",
    "from models.dataset import MotionECoGDataset\n",
    "\n",
    "from torch.utils.data import Subset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Model Classes\n",
    "from models.variational_motion_encoder import VariationalMotionEncoder\n",
    "from models.waveform_decoder import WaveformDecoder\n",
    "from models.variational_waveform_encoder import VariationalWaveformEncoder\n",
    "from models.motion_decoder import MotionDecoder\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.graph_objects as go\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Paths to models\n",
    "model_paths = {\n",
    "    \"motion_encoder\": \"../models/motion_encoder_best.pt\",\n",
    "    \"waveform_decoder\": \"../models/waveform_decoder_best.pt\",\n",
    "    \"waveform_encoder\": \"../models/waveform_encoder_best.pt\",\n",
    "    \"motion_decoder\": \"../models/motion_decoder_best.pt\",\n",
    "}\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd584c40",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "033c42e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = MotionECoGDataset(MOTION_NP, ECOG_NP)\n",
    "test_indices = torch.load(\"../models/test_indices.pt\")\n",
    "test_dataset = Subset(dataset, test_indices)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False, drop_last=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90c14326",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiating the Model Classes\n",
    "\n",
    "# Initialize models\n",
    "latent_dim = 128\n",
    "motion_encoder = VariationalMotionEncoder(latent_dim=latent_dim).to(device)\n",
    "# MotionEncoder(latent_dim).to(device)\n",
    "waveform_decoder = WaveformDecoder(latent_dim=latent_dim).to(device)\n",
    "waveform_encoder = VariationalWaveformEncoder(\n",
    "    input_dim=64, hidden_dim=128, latent_dim=128\n",
    ").to(device)\n",
    "# WaveformEncoder(latent_dim).to(device)\n",
    "motion_decoder = MotionDecoder(latent_dim).to(device)\n",
    "\n",
    "# Load the Models\n",
    "motion_encoder.load_state_dict(torch.load(model_paths[\"motion_encoder\"], map_location=device))\n",
    "waveform_decoder.load_state_dict(torch.load(model_paths[\"waveform_decoder\"], map_location=device))\n",
    "waveform_encoder.load_state_dict(torch.load(model_paths[\"waveform_encoder\"], map_location=device))\n",
    "motion_decoder.load_state_dict(torch.load(model_paths[\"motion_decoder\"], map_location=device))\n",
    "\n",
    "# Set to eval mode\n",
    "motion_encoder.eval()\n",
    "waveform_decoder.eval()\n",
    "waveform_encoder.eval()\n",
    "motion_decoder.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "738e15e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "GLOBAL_MOTION_STD = np.load('../data/global_motion_std.npy')\n",
    "GLOBAL_MOTION_MEAN = np.load('../data/global_motion_mean.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44b10ba9",
   "metadata": {},
   "source": [
    "## Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53cd4e0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "motion_np = \"../data/motion_values_normalized.npy\"\n",
    "ecog_np = \"../data/ecog_values_normalized.npy\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91aea0db",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_split = 0.2\n",
    "test_split = 0.1\n",
    "batch_size = 128\n",
    "epochs=300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00b0dc21",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = MotionECoGDataset(motion_np, ecog_np)\n",
    "total_length = len(dataset)\n",
    "test_size = int(test_split * total_length)\n",
    "remaining_size = total_length - test_size\n",
    "val_size = int(val_split * remaining_size)\n",
    "train_size = remaining_size - val_size\n",
    "train_dataset, val_dataset, test_dataset = random_split(\n",
    "    dataset, [train_size, val_size, test_size]\n",
    ")\n",
    "train_loader = DataLoader(\n",
    "    train_dataset, batch_size=batch_size, shuffle=True, drop_last=True\n",
    ")\n",
    "val_loader = DataLoader(\n",
    "    val_dataset, batch_size=batch_size, shuffle=False, drop_last=True\n",
    ")\n",
    "test_loader = DataLoader(\n",
    "    test_dataset, batch_size=batch_size, shuffle=False, drop_last=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a99e3dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(epochs):\n",
    "    for batch in tqdm(test_dataset_sample.indices[\"test_indices\"], desc=f\"Epoch {epoch+1}/{epochs}\"):\n",
    "                motion = batch[\"motion\"].to(device)\n",
    "                ecog = batch[\"ecog\"].to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b83906a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f401519",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset.indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfb1a852",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_sample = MotionECoGDataset(MOTION_NP, ECOG_NP)\n",
    "test_indices_sample = torch.load(\"../models/test_indices.pt\")\n",
    "test_dataset_sample = Subset(dataset_sample, test_indices_sample)\n",
    "test_loader_sample = DataLoader(test_dataset_sample, batch_size=64, shuffle=False, drop_last=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd190cfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(epochs):\n",
    "    for batch in tqdm(test_loader_sample, desc=f\"Epoch {epoch+1}/{epochs}\"):\n",
    "                motion = batch[\"motion\"].to(device)\n",
    "                ecog = batch[\"ecog\"].to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a72149d",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76f3e677",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c03c92ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader_2 = DataLoader(\n",
    "    test_dataset_sample, batch_size=batch_size, shuffle=False, drop_last=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e10e7fd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "837de8b6",
   "metadata": {},
   "source": [
    "## Reconstruction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86496f3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Collect motion predictions\n",
    "predicted_coordinates = []\n",
    "actual_coordinates = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in tqdm(test_loader, desc=\"Generating Motion Predictions\"):\n",
    "        motion = batch[\"motion\"].to(device)\n",
    "        ecog = batch[\"ecog\"].to(device)\n",
    "\n",
    "        # Full latent pass\n",
    "        motion_latent, _, _ = motion_encoder(motion)\n",
    "        ecog_synth = waveform_decoder(motion_latent)\n",
    "        waveform_latent, _, _ = waveform_encoder(ecog_synth)\n",
    "        motion_reconstructed = motion_decoder(waveform_latent)\n",
    "\n",
    "        # motion_reconstructed shape: (B, 3)\n",
    "        # Normalize back to the real space\n",
    "\n",
    "        predicted_coordinates.append((motion_reconstructed.cpu().numpy() * GLOBAL_MOTION_STD) + GLOBAL_MOTION_MEAN)\n",
    "        actual_coordinates.append((motion.cpu().numpy() * GLOBAL_MOTION_STD) + GLOBAL_MOTION_MEAN)\n",
    "\n",
    "predicted_coords = np.concatenate(predicted_coordinates, axis=0)\n",
    "actual_coordinates = np.concatenate(actual_coordinates, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50f46d26",
   "metadata": {},
   "source": [
    "## Visualization\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8503e33b",
   "metadata": {},
   "source": [
    "### Single Instance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "098ea2f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "import numpy as np\n",
    "\n",
    "# Downsample for clarity (every 10th point)\n",
    "step = 10\n",
    "actual = actual_coordinates[::step]\n",
    "predicted = predicted_coords[::step]\n",
    "\n",
    "fig = go.Figure()\n",
    "\n",
    "# Actual Trajectory\n",
    "fig.add_trace(go.Scatter3d(\n",
    "    x=actual[:, 0], y=actual[:, 1], z=actual[:, 2],\n",
    "    mode='lines+markers',\n",
    "    marker=dict(size=3, color='green'),\n",
    "    line=dict(color='green', width=4),\n",
    "    name='Actual Motion'\n",
    "))\n",
    "\n",
    "# Predicted Trajectory\n",
    "fig.add_trace(go.Scatter3d(\n",
    "    x=predicted[:, 0], y=predicted[:, 1], z=predicted[:, 2],\n",
    "    mode='lines+markers',\n",
    "    marker=dict(size=3, color='red'),\n",
    "    line=dict(color='red', width=4),\n",
    "    name='Predicted Motion'\n",
    "))\n",
    "\n",
    "fig.update_layout(\n",
    "    title=\"Predicted vs Actual 3D Wrist Motion\",\n",
    "    scene=dict(\n",
    "        xaxis_title='X',\n",
    "        yaxis_title='Y',\n",
    "        zaxis_title='Z',\n",
    "    ),\n",
    "    margin=dict(l=0, r=0, b=0, t=40),\n",
    "    legend=dict(x=0.7, y=0.9)\n",
    ")\n",
    "\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "198b86d3",
   "metadata": {},
   "source": [
    "### Temporal Development Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7c26890",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "import numpy as np\n",
    "n_frames = 1\n",
    "# Downsample\n",
    "step = 10\n",
    "actual = actual_coordinates[::step]\n",
    "predicted = predicted_coords[::step]\n",
    "N = actual.shape[0]\n",
    "\n",
    "# Create frames\n",
    "frames = [\n",
    "    go.Frame(\n",
    "        data=[\n",
    "            go.Scatter3d(\n",
    "                x=actual[:k, 0], y=actual[:k, 1], z=actual[:k, 2],\n",
    "                mode='lines+markers',\n",
    "                line=dict(color='green', width=4),\n",
    "                marker=dict(size=3, color='green'),\n",
    "                name='Actual'\n",
    "            ),\n",
    "            go.Scatter3d(\n",
    "                x=predicted[:k, 0], y=predicted[:k, 1], z=predicted[:k, 2],\n",
    "                mode='lines+markers',\n",
    "                line=dict(color='red', width=4),\n",
    "                marker=dict(size=3, color='red'),\n",
    "                name='Predicted'\n",
    "            )\n",
    "        ],\n",
    "        name=str(k)\n",
    "    )\n",
    "    for k in range(1, N + 1)\n",
    "]\n",
    "\n",
    "# Initial trace\n",
    "fig = go.Figure(data=[\n",
    "    go.Scatter3d(\n",
    "        x=[actual[0, 0]], y=[actual[0, 1]], z=[actual[0, 2]],\n",
    "        mode='markers', marker=dict(size=5, color='green'), name='Actual'\n",
    "    ),\n",
    "    go.Scatter3d(\n",
    "        x=[predicted[0, 0]], y=[predicted[0, 1]], z=[predicted[0, 2]],\n",
    "        mode='markers', marker=dict(size=5, color='red'), name='Predicted'\n",
    "    )\n",
    "], frames=frames)\n",
    "\n",
    "# Layout and controls\n",
    "fig.update_layout(\n",
    "    title='Animated 3D Wrist Motion: Predicted vs Actual',\n",
    "    scene=dict(\n",
    "        xaxis=dict(range=[min(actual[:, 0].min(), predicted[:, 0].min()),\n",
    "                          max(actual[:, 0].max(), predicted[:, 0].max())], title='X'),\n",
    "        yaxis=dict(range=[min(actual[:, 1].min(), predicted[:, 1].min()),\n",
    "                          max(actual[:, 1].max(), predicted[:, 1].max())], title='Y'),\n",
    "        zaxis=dict(range=[min(actual[:, 2].min(), predicted[:, 2].min()),\n",
    "                          max(actual[:, 2].max(), predicted[:, 2].max())], title='Z'),\n",
    "    ),\n",
    "    updatemenus=[dict(\n",
    "        type='buttons',\n",
    "        showactive=False,\n",
    "        buttons=[\n",
    "            dict(\n",
    "                label='Play',\n",
    "                method='animate',\n",
    "                args=[None, dict(frame=dict(duration=20, redraw=True), fromcurrent=True, mode='immediate')]\n",
    "            ),\n",
    "            dict(\n",
    "                label='Pause',\n",
    "                method='animate',\n",
    "                args=[[None], dict(frame=dict(duration=0, redraw=False), mode='immediate')]\n",
    "            )\n",
    "        ],\n",
    "        x=0.1, y=0, xanchor='right', yanchor='top'\n",
    "    )],\n",
    "    sliders=[dict(\n",
    "        active=0,\n",
    "        pad=dict(t=50),\n",
    "        steps=[\n",
    "            dict(\n",
    "                method='animate',\n",
    "                args=[[str(k)], dict(mode='immediate', frame=dict(duration=0, redraw=True), transition=dict(duration=0))],\n",
    "                label=str(k)\n",
    "            )\n",
    "            for k in range(1, N + 1, n_frames)\n",
    "        ]\n",
    "    )]\n",
    ")\n",
    "\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c1e30de",
   "metadata": {},
   "source": [
    "## Simulating Spams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "632dd0b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Physical Movements with introduced jitter\n",
    "# Create Synthetic Waveforms from this new dataset\n",
    "# Detect Anomalies in the synthetic waveforms in real time\n",
    "# Calculate the Counter Current\n",
    "# Calculate the Adjusted Signal after this current is introduced\n",
    "# Reconstruct the physical motion (proceed as normal) \n",
    "# Evaluate Results (Original Motion should be the same as Hyperpolarized Reconstructed Spasm Motion)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2b1769b",
   "metadata": {},
   "source": [
    "## Detecting Onset of Spams (Anomalies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "921a3258",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "62c34c77",
   "metadata": {},
   "source": [
    "## Hodgkin & Huxley Calculation of Current to Induce Hyperpolarization and prevent Simulated Spasms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a8db058",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7dc57077",
   "metadata": {},
   "source": [
    "## Simulate Detecting Onset and Preventing Spasms to Create Laminar or Normal Healthy Motion "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
